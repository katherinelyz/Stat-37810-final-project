---
title: "STAT 37810 Final Project #3: K-Means"
author: "Yingzhao Li & Linlin Wu"
date: "Nov. 1st, 2016"
output: html_document
---

## Install packages
Package "rattle" is required for calling the wine data.

Package "fpc" is required for ploting the k means.

Package "fields" is required for calculating the Euclidean distance. 

Package "flexclust" is required for quantifying the algorithm.

```{r packages,eval=FALSE}
install.packages("rattle")
install.packages("fpc")
install.packages("fields")
install.packages("flexclust")
```

### Note
Please install all required package before running the following code.

```{r library,include=FALSE}
library(rattle)
library(fpc)
library(fields)
library(flexclust)
```

## K-Means function
The K means function is defined as below. Euclidean distance measure method is used in the k-means function.

```{r k means algorithm}
# The K means algorithm
k_means <- function(x, centers, iteration=10) { 
    # Iteration default is 10 as build-in function kmeans
  oldcluster <- vector(iteration, mode="list")
  oldcenter <- vector(iteration, mode="list")
  
  for(i in 1:iteration) {
    # Euclidean distance measure
    centerdist <- rdist(x, centers) 
    clusters <- apply(centerdist, 1, which.min)
    centers <- apply(x, 2, tapply, clusters, mean)
    # Saving history
    oldcluster <- clusters
    oldcenter <- centers
  }
  
  list(clusters = oldcluster, centers = oldcenter)
}
```

## Implement K-Means

### Wine data

```{r kmeans}
# Call wine dataset and exclude the "Type" variable
data <- (wine[-1]) 

ktest <- as.matrix(data)
centers <- ktest[sample(nrow(ktest), 3),]
result <- k_means(ktest, centers, 10)
plotcluster(data, result$clusters)
```

As we can see from the plot, the clusters are not very well seperated. There are some overlaps between each cluster.

To quantify how well the algorithm's clusters correspond to the wine types, we will use the rand index.

First, cross-tabulation is used to compare the k means clusters and the original classes of the dataset, which is the types of wines.

```{r randindex}
cross.tab <- table(wine$Type, result$clusters)
randIndex(cross.tab)
```

The rand index gives the measure of the agreement between two partitions, adjusted for chance. It ranges from -1 (no agreement) to 1 (perfect agreement).

In our case, the rand index is around 0.4, which indicates that the agreement between the wine type and the cluster solution is not very strong.

### Scaled wine data

```{r scaled data}
data2 <- scale(data) 
```

This command scales the orgininal data. We need to scale the data to perform accuracy of distance of each clusters. The k-means minimizes the error function, so normalizing the data improves convergence of such algorithms.

```{r kmeans for scaled data}
ktest2 <- as.matrix(data2)
centers2 <- ktest2[sample(nrow(ktest2), 3),]
result2 <- k_means(ktest2, centers2, 10)
plotcluster(data2, result2$clusters)
```

Repeat the steps using scaled wine data. 

Now, the data is clustered very well, with no overlaps between clusters.

```{r randindex after scale}
cross.tab2 <- table(wine$Type, result2$clusters)
randIndex(cross.tab2)
```

After the data is scaled, the rand index becomes very strong, which is around 0.9. The scaled clusters correspond to the three wine types very well.

### Iris data

```{r iris}
# Call iris dataset
data(iris) 

# Remove the "species" variable
data.iris <- iris[-5] 

# Repeat the steps
ktest.iris <- as.matrix(data.iris)
centers.iris <- ktest.iris[sample(nrow(ktest.iris), 3),]
result.iris <- k_means(ktest.iris, centers.iris, 10)
plotcluster(data.iris, result.iris$clusters)
```

From the plot, we can see that 2 clusters are not well seperated.

```{r iris rand index}
cross.tab.iris<-table(iris$Species,result.iris$clusters)
randIndex(cross.tab.iris)
```

The rand index is around 0.7, which indicates that the agreement between the iris species and the cluster solution is not very strong.

### Scaled iris data

```{r scaled iris}
data2.iris <- scale(data.iris)

ktest2.iris <- as.matrix(data2.iris)
centers2.iris <- ktest2.iris[sample(nrow(ktest2.iris), 3),]
result2.iris <- k_means(ktest2.iris, centers2.iris, 10)
plotcluster(data2.iris, result2.iris$clusters)
```

After the iris data is scaled, the clusters still have overlaps.

```{r scaled iris rand index}
cross.tab2.iris<-table(iris$Species,result2.iris$clusters)
randIndex(cross.tab2.iris)
```

The rand index of scaled iris is close to that of the original data. The agreement between iris species and the scaled clusters is still not strong.

K means does not work well for classifying the iris data. Scaling does not improve classifying it.